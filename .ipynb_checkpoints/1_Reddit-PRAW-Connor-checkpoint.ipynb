{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc426077-0da2-49af-8e9f-e7a27ebaadd9",
   "metadata": {},
   "source": [
    "# **1. Install PRAW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3e56be-a4bf-43d4-8c57-7f9954b44b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install praw\n",
    "import praw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ecd0ed-d601-4b45-b545-639d4a1e7b49",
   "metadata": {},
   "source": [
    "# **2. Create a Reddit App**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da49f3cc-1cec-4917-90f4-7b639d7a145a",
   "metadata": {},
   "source": [
    "To access the Reddit API, you'll need to create an application on Reddit and obtain your API credentials. Follow these steps:\n",
    "\n",
    "- Go to the Reddit website (https://www.reddit.com/) and log in to your account. Feel free to create a throwaway account for this project!\n",
    "- Navigate to the Reddit Apps page (https://www.reddit.com/prefs/apps).\n",
    "- Click the \"are you a developer? create an app...\" button in the top left.\n",
    "- Provide a name for your app (e.g., \"PRAW\"), select the app type ('script') , and optionally add a description. Use http://localhost:8080 as your redirect URI.\n",
    "- After submitting the form, you will reach a page that looks like the following image. You'll see your application's details, including the client ID and client secret. Keep these credentials handy for the next step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3997780-adc4-4ee2-91e3-6a296587cdf8",
   "metadata": {},
   "source": [
    "![Praw](https://www.honchosearch.com/hubfs/Imported_Blog_Media/Client-ID-Client-Secret.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b71b52e-05db-4a47-8c8c-ec8f4fd9c283",
   "metadata": {},
   "source": [
    "# **3. Initialize PRAW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "103d7151-cf2e-47cb-82c2-578faa763888",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id = 'bH4RU2bXmyXbuwcX1757_A',\n",
    "    client_secret='gF99Z7zQ3e-3Wt8II5MIYfnl8b6vlg',\n",
    "    user_agent='ConnorDSB521',\n",
    "    username='JaydadCTatumthe1st',\n",
    "    password='papimvp_34'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204db51a-ee1d-4180-839b-67bdecea4fe5",
   "metadata": {},
   "source": [
    "Replace 'YOUR_CLIENT_ID', 'YOUR_CLIENT_SECRET', 'YOUR_USER_AGENT', 'YOUR_REDDIT_USERNAME', and 'YOUR_REDDIT_PASSWORD' with your actual Reddit API credentials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b298a6-1aa9-4690-8447-6f717c24e9cc",
   "metadata": {},
   "source": [
    "Your user agent is an identifier used by reddit to identify the source of requests. You can make it whatever you want, but you'll want to choose something descriptive and unique, and it's recommended that your username is included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9006de6-d5ce-4537-a9c7-ca5bdd4ee630",
   "metadata": {},
   "source": [
    "**I have removed my own credentials from this workbook. We can show you how to hide your credentials before submitting the project! The following code will need your own credentials in order to successfully work.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072ea3ea-ab20-4fe5-8711-dbe220400fa3",
   "metadata": {},
   "source": [
    "# 4. Take a look at the documentation [here](https://praw.readthedocs.io/)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17aa261b-f63a-4437-ac41-242982cb546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is JUST an example of how you can use PRAW\n",
    "\n",
    "# Choose your subreddit\n",
    "#subreddit = reddit.subreddit('politics')\n",
    "\n",
    "# Adjust the limit as needed -- Note that this will grab the 25 most recent posts\n",
    "#posts = subreddit.hot(limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8eb1f6-449f-4bc9-9d56-1fe03739ff50",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "- Reddit API Limitations: The Reddit API imposes limitations on the number of posts you can retrieve in a single request. The maximum number of posts per request is typically 100. Therefore, if you set the limit parameter to a value greater than 100, PRAW will make multiple requests behind the scenes to fetch the desired number of posts.\n",
    "- Rate Limiting: The Reddit API also enforces rate limits to prevent abuse and ensure fair usage. The specific rate limits can vary depending on factors such as your Reddit account's age and karma. As a standard user, you're typically allowed to make 60 requests per minute. If you exceed the rate limit, you may receive an error response until the rate limit resets.\n",
    "- TIP: You can use the created_utc attribute of a post to keep track of the timestamp and ensure non-overlapping pulls. The created_utc attribute represents the post's creation time in UTC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1b221e2-244d-42dc-9c89-1d04134fc7d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing post 1dy8qjl: received 429 HTTP response\n",
      "Error processing post 1dv9zdj: received 429 HTTP response\n",
      "Error processing post 1dvum00: received 429 HTTP response\n",
      "Error processing post 1dz1lk8: received 429 HTTP response\n",
      "Error processing post 1dwomir: received 429 HTTP response\n",
      "Error processing post 1duo2mp: received 429 HTTP response\n",
      "Error processing post 1dv38zy: received 429 HTTP response\n",
      "Error processing post 1dudhc8: received 429 HTTP response\n",
      "Error processing post 1dubuqz: received 429 HTTP response\n",
      "Error processing post 1dv810w: received 429 HTTP response\n",
      "Error processing post 1dyk7kv: received 429 HTTP response\n",
      "Error processing post 1dx20a6: received 429 HTTP response\n",
      "Error processing post 1dxf1bw: received 429 HTTP response\n",
      "Error processing post 1dy1s0q: received 429 HTTP response\n",
      "Error processing post 1dw5jra: received 429 HTTP response\n",
      "Error processing post 1dv555m: received 429 HTTP response\n",
      "Error processing post 1dxhbt2: received 429 HTTP response\n",
      "Error processing post 1dx17fe: received 429 HTTP response\n",
      "Directory 'scraping_data' already exists.\n",
      "DataFrame saved to scraping_data/politics_top_past_wk_2024-07-10_06-27-54.csv\n",
      "    created_utc                                              title selftext  \\\n",
      "0  1.720234e+09  Trump World ‘panicking’ as Project 2025 gets o...            \n",
      "1           NaN                                               None     None   \n",
      "2           NaN                                               None     None   \n",
      "3           NaN                                               None     None   \n",
      "4           NaN                                               None     None   \n",
      "\n",
      "  subreddit                                           comments  num_comments  \n",
      "0  politics  [[This needs to be the talking point for the r...        2344.0  \n",
      "1      None                                               None           NaN  \n",
      "2      None                                               None           NaN  \n",
      "3      None                                               None           NaN  \n",
      "4      None                                               None           NaN  \n"
     ]
    }
   ],
   "source": [
    "subreddit_name = 'politics'\n",
    "subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "posts = subreddit.top(time_filter='week', limit=30)\n",
    "# making a function to use on various post calls\n",
    "def process_post(post):\n",
    "    try:\n",
    "        # this gets all of the comments in a post\n",
    "        post.comments.replace_more(limit=None)\n",
    "        #sorting the comments by score\n",
    "        comments_sorted = sorted(\n",
    "            [[comment.body, comment.score] for comment in post.comments.list()],\n",
    "            key=lambda x: x[1], reverse=True\n",
    "        )\n",
    "        num_comments = len(comments_sorted)\n",
    "        #creates a list of all of my desired attributes\n",
    "        return [post.created_utc, post.title, post.selftext, post.subreddit.display_name, comments_sorted, num_comments]\n",
    "    #exception handler in case praw is rate limiting me\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing post {post.id}: {e}\")\n",
    "        return [None] * 6\n",
    "\n",
    "data = []\n",
    "#creating a numpy array of all of the posts and calling the function on \n",
    "for post in posts:\n",
    "    data.append(process_post(post))\n",
    "\n",
    "#creating the columns for my data and casting the numpy array as a dataframe\n",
    "columns = ['created_utc', 'title', 'selftext', 'subreddit', 'comments', 'num_comments']\n",
    "politics = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "#saving my data using the exact datetime so my data can't be overwritten\n",
    "current_time = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "directory = 'scraping_data'\n",
    "if not os.path.exists(directory):\n",
    "    os.mkdir(directory)\n",
    "    print(f\"Directory '{directory}' created.\")\n",
    "else:\n",
    "    print(f\"Directory '{directory}' already exists.\")\n",
    "filename = f'{directory}/{subreddit_name}_top_past_wk_{current_time}.csv'\n",
    "\n",
    "politics.to_csv(filename, index=False)\n",
    "\n",
    "#printing my data once my code finishes\n",
    "print(f\"DataFrame saved to {filename}\")\n",
    "print(politics.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e82bb8be-c948-44a1-9718-2189197b56c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>comments</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.719492e+09</td>\n",
       "      <td>Three female GOP state senators who filibuster...</td>\n",
       "      <td></td>\n",
       "      <td>politics</td>\n",
       "      <td>[[\\nAs a reminder, this subreddit [is for civi...</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.719499e+09</td>\n",
       "      <td>Jack Smith brings receipts of vile threats aga...</td>\n",
       "      <td></td>\n",
       "      <td>politics</td>\n",
       "      <td>[[\\nAs a reminder, this subreddit [is for civi...</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.719502e+09</td>\n",
       "      <td>MAGA Loses It Over Game-Changing Announcement ...</td>\n",
       "      <td></td>\n",
       "      <td>politics</td>\n",
       "      <td>[[\\nAs a reminder, this subreddit [is for civi...</td>\n",
       "      <td>858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.719495e+09</td>\n",
       "      <td>Tonight’s debate could be Trump’s last act: Th...</td>\n",
       "      <td></td>\n",
       "      <td>politics</td>\n",
       "      <td>[[\\nAs a reminder, this subreddit [is for civi...</td>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.719510e+09</td>\n",
       "      <td>MAGA Fumes Over New Microphone Rule at Biden-T...</td>\n",
       "      <td></td>\n",
       "      <td>politics</td>\n",
       "      <td>[[\\nAs a reminder, this subreddit [is for civi...</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    created_utc                                              title selftext  \\\n",
       "0  1.719492e+09  Three female GOP state senators who filibuster...            \n",
       "1  1.719499e+09  Jack Smith brings receipts of vile threats aga...            \n",
       "2  1.719502e+09  MAGA Loses It Over Game-Changing Announcement ...            \n",
       "3  1.719495e+09  Tonight’s debate could be Trump’s last act: Th...            \n",
       "4  1.719510e+09  MAGA Fumes Over New Microphone Rule at Biden-T...            \n",
       "\n",
       "  subreddit                                           comments  num_comments  \n",
       "0  politics  [[\\nAs a reminder, this subreddit [is for civi...           447  \n",
       "1  politics  [[\\nAs a reminder, this subreddit [is for civi...           190  \n",
       "2  politics  [[\\nAs a reminder, this subreddit [is for civi...           858  \n",
       "3  politics  [[\\nAs a reminder, this subreddit [is for civi...          1193  \n",
       "4  politics  [[\\nAs a reminder, this subreddit [is for civi...           330  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46307d7c-3799-4550-9ac9-eca022a0d1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "979bbb5b-4f87-404d-8d10-7fefb5b96f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "346532db-95e5-4fe1-b5b1-f6d2cc4d6e85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a6e82a6-2ace-4776-90a2-214a9d619483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-09_09-59-02\n"
     ]
    }
   ],
   "source": [
    "current_time = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "print(current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82ecd4eb-7810-4ed9-84cc-0cd2719b1835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d5c3a3b-6f44-410c-b901-c2ba4867443b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'scraping_data' already exists.\n"
     ]
    }
   ],
   "source": [
    "directory = 'scraping_data'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d3053699-7acc-49b8-ba2f-231f2431956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = f'{directory}/politics_{current_time}.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89704496-e819-4908-8da2-cf4d5841774d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scraping_data/politics_2024-06-27_16-12-02.csv'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c5dde75-b045-4906-a1d0-a14a1bbd7997",
   "metadata": {},
   "outputs": [],
   "source": [
    "politics.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb4c19d-f9d9-4be8-9ca5-5ecbbde48970",
   "metadata": {},
   "source": [
    "Remember, you will need to pull *at least* 1000 posts from each subreddit, not just 25. Like I mentioned above, you can use the created_utc attribute of a post to keep track of the timestamp and ensure non-overlapping pulls. We will leave this work for you all to complete.\n",
    "\n",
    "Once you have at least 1000 posts from each subreddit, you can do some EDA (perhaps maybe the most common words in each subreddit..?) Eventually, you will want to combine your two dataframes together to do modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0785dc1-075d-4bd4-8c34-4dd2978d7dfb",
   "metadata": {},
   "source": [
    "### Hopefully this is enough of a tutorial to help get you started! If you have any questions, let us know!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f942833-8fdb-46d1-9182-b672e49434a5",
   "metadata": {},
   "source": [
    "### Note: Rather than working in this template notebook, make a brand new \"scraping\" notebook (or script), with your own comments, so you can use this project in a portfolio!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
